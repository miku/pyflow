{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sqrt(i ** 2) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=2)(delayed(sqrt)(i ** 2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "p = Parallel(n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(p, typing.Callable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m      \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mType:\u001b[0m           Parallel\n",
      "\u001b[0;31mString form:\u001b[0m    Parallel(n_jobs=2)\n",
      "\u001b[0;31mFile:\u001b[0m           ~/code/miku/pyflow/.venv/lib/python3.12/site-packages/joblib/parallel.py\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Helper class for readable parallel mapping.\n",
      "\n",
      "Read more in the :ref:`User Guide <parallel>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_jobs: int, default=None\n",
      "    The maximum number of concurrently running jobs, such as the number\n",
      "    of Python worker processes when ``backend=\"loky\"`` or the size of\n",
      "    the thread-pool when ``backend=\"threading\"``.\n",
      "    This argument is converted to an integer, rounded below for float.\n",
      "    If -1 is given, `joblib` tries to use all CPUs. The number of CPUs\n",
      "    ``n_cpus`` is obtained with :func:`~cpu_count`.\n",
      "    For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. For instance,\n",
      "    using ``n_jobs=-2`` will result in all CPUs but one being used.\n",
      "    This argument can also go above ``n_cpus``, which will cause\n",
      "    oversubscription. In some cases, slight oversubscription can be\n",
      "    beneficial, e.g., for tasks with large I/O operations.\n",
      "    If 1 is given, no parallel computing code is used at all, and the\n",
      "    behavior amounts to a simple python `for` loop. This mode is not\n",
      "    compatible with ``timeout``.\n",
      "    None is a marker for 'unset' that will be interpreted as n_jobs=1\n",
      "    unless the call is performed under a :func:`~parallel_config`\n",
      "    context manager that sets another value for ``n_jobs``.\n",
      "    If n_jobs = 0 then a ValueError is raised.\n",
      "backend: str, ParallelBackendBase instance or None, default='loky'\n",
      "    Specify the parallelization backend implementation.\n",
      "    Supported backends are:\n",
      "\n",
      "    - \"loky\" used by default, can induce some\n",
      "      communication and memory overhead when exchanging input and\n",
      "      output data with the worker Python processes. On some rare\n",
      "      systems (such as Pyiodide), the loky backend may not be\n",
      "      available.\n",
      "    - \"multiprocessing\" previous process-based backend based on\n",
      "      `multiprocessing.Pool`. Less robust than `loky`.\n",
      "    - \"threading\" is a very low-overhead backend but it suffers\n",
      "      from the Python Global Interpreter Lock if the called function\n",
      "      relies a lot on Python objects. \"threading\" is mostly useful\n",
      "      when the execution bottleneck is a compiled extension that\n",
      "      explicitly releases the GIL (for instance a Cython loop wrapped\n",
      "      in a \"with nogil\" block or an expensive call to a library such\n",
      "      as NumPy).\n",
      "    - finally, you can register backends by calling\n",
      "      :func:`~register_parallel_backend`. This will allow you to\n",
      "      implement a backend of your liking.\n",
      "\n",
      "    It is not recommended to hard-code the backend name in a call to\n",
      "    :class:`~Parallel` in a library. Instead it is recommended to set\n",
      "    soft hints (prefer) or hard constraints (require) so as to make it\n",
      "    possible for library users to change the backend from the outside\n",
      "    using the :func:`~parallel_config` context manager.\n",
      "return_as: str in {'list', 'generator', 'generator_unordered'}, default='list'\n",
      "    If 'list', calls to this instance will return a list, only when\n",
      "    all results have been processed and retrieved.\n",
      "    If 'generator', it will return a generator that yields the results\n",
      "    as soon as they are available, in the order the tasks have been\n",
      "    submitted with.\n",
      "    If 'generator_unordered', the generator will immediately yield\n",
      "    available results independently of the submission order. The output\n",
      "    order is not deterministic in this case because it depends on the\n",
      "    concurrency of the workers.\n",
      "prefer: str in {'processes', 'threads'} or None, default=None\n",
      "    Soft hint to choose the default backend if no specific backend\n",
      "    was selected with the :func:`~parallel_config` context manager.\n",
      "    The default process-based backend is 'loky' and the default\n",
      "    thread-based backend is 'threading'. Ignored if the ``backend``\n",
      "    parameter is specified.\n",
      "require: 'sharedmem' or None, default=None\n",
      "    Hard constraint to select the backend. If set to 'sharedmem',\n",
      "    the selected backend will be single-host and thread-based even\n",
      "    if the user asked for a non-thread based backend with\n",
      "    :func:`~joblib.parallel_config`.\n",
      "verbose: int, default=0\n",
      "    The verbosity level: if non zero, progress messages are\n",
      "    printed. Above 50, the output is sent to stdout.\n",
      "    The frequency of the messages increases with the verbosity level.\n",
      "    If it more than 10, all iterations are reported.\n",
      "timeout: float or None, default=None\n",
      "    Timeout limit for each task to complete.  If any task takes longer\n",
      "    a TimeOutError will be raised. Only applied when n_jobs != 1\n",
      "pre_dispatch: {'all', integer, or expression, as in '3*n_jobs'}, default='2*n_jobs'\n",
      "    The number of batches (of tasks) to be pre-dispatched.\n",
      "    Default is '2*n_jobs'. When batch_size=\"auto\" this is reasonable\n",
      "    default and the workers should never starve. Note that only basic\n",
      "    arithmetics are allowed here and no modules can be used in this\n",
      "    expression.\n",
      "batch_size: int or 'auto', default='auto'\n",
      "    The number of atomic tasks to dispatch at once to each\n",
      "    worker. When individual evaluations are very fast, dispatching\n",
      "    calls to workers can be slower than sequential computation because\n",
      "    of the overhead. Batching fast computations together can mitigate\n",
      "    this.\n",
      "    The ``'auto'`` strategy keeps track of the time it takes for a\n",
      "    batch to complete, and dynamically adjusts the batch size to keep\n",
      "    the time on the order of half a second, using a heuristic. The\n",
      "    initial batch size is 1.\n",
      "    ``batch_size=\"auto\"`` with ``backend=\"threading\"`` will dispatch\n",
      "    batches of a single task at a time as the threading backend has\n",
      "    very little overhead and using larger batch size has not proved to\n",
      "    bring any gain in that case.\n",
      "temp_folder: str or None, default=None\n",
      "    Folder to be used by the pool for memmapping large arrays\n",
      "    for sharing memory with worker processes. If None, this will try in\n",
      "    order:\n",
      "\n",
      "    - a folder pointed by the JOBLIB_TEMP_FOLDER environment\n",
      "      variable,\n",
      "    - /dev/shm if the folder exists and is writable: this is a\n",
      "      RAM disk filesystem available by default on modern Linux\n",
      "      distributions,\n",
      "    - the default system temporary folder that can be\n",
      "      overridden with TMP, TMPDIR or TEMP environment\n",
      "      variables, typically /tmp under Unix operating systems.\n",
      "\n",
      "    Only active when ``backend=\"loky\"`` or ``\"multiprocessing\"``.\n",
      "max_nbytes int, str, or None, optional, default='1M'\n",
      "    Threshold on the size of arrays passed to the workers that\n",
      "    triggers automated memory mapping in temp_folder. Can be an int\n",
      "    in Bytes, or a human-readable string, e.g., '1M' for 1 megabyte.\n",
      "    Use None to disable memmapping of large arrays.\n",
      "    Only active when ``backend=\"loky\"`` or ``\"multiprocessing\"``.\n",
      "mmap_mode: {None, 'r+', 'r', 'w+', 'c'}, default='r'\n",
      "    Memmapping mode for numpy arrays passed to workers. None will\n",
      "    disable memmapping, other modes defined in the numpy.memmap doc:\n",
      "    https://numpy.org/doc/stable/reference/generated/numpy.memmap.html\n",
      "    Also, see 'max_nbytes' parameter documentation for more details.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "\n",
      "This object uses workers to compute in parallel the application of a\n",
      "function to many different arguments. The main functionality it brings\n",
      "in addition to using the raw multiprocessing or concurrent.futures API\n",
      "are (see examples for details):\n",
      "\n",
      "* More readable code, in particular since it avoids\n",
      "  constructing list of arguments.\n",
      "\n",
      "* Easier debugging:\n",
      "    - informative tracebacks even when the error happens on\n",
      "      the client side\n",
      "    - using 'n_jobs=1' enables to turn off parallel computing\n",
      "      for debugging without changing the codepath\n",
      "    - early capture of pickling errors\n",
      "\n",
      "* An optional progress meter.\n",
      "\n",
      "* Interruption of multiprocesses jobs with 'Ctrl-C'\n",
      "\n",
      "* Flexible pickling control for the communication to and from\n",
      "  the worker processes.\n",
      "\n",
      "* Ability to use shared memory efficiently with worker\n",
      "  processes for large numpy-based datastructures.\n",
      "\n",
      "Note that the intended usage is to run one call at a time. Multiple\n",
      "calls to the same Parallel object will result in a ``RuntimeError``\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "A simple example:\n",
      "\n",
      ">>> from math import sqrt\n",
      ">>> from joblib import Parallel, delayed\n",
      ">>> Parallel(n_jobs=1)(delayed(sqrt)(i**2) for i in range(10))\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n",
      "\n",
      "Reshaping the output when the function has several return\n",
      "values:\n",
      "\n",
      ">>> from math import modf\n",
      ">>> from joblib import Parallel, delayed\n",
      ">>> r = Parallel(n_jobs=1)(delayed(modf)(i/2.) for i in range(10))\n",
      ">>> res, i = zip(*r)\n",
      ">>> res\n",
      "(0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5)\n",
      ">>> i\n",
      "(0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0)\n",
      "\n",
      "The progress meter: the higher the value of `verbose`, the more\n",
      "messages:\n",
      "\n",
      ">>> from time import sleep\n",
      ">>> from joblib import Parallel, delayed\n",
      ">>> r = Parallel(n_jobs=2, verbose=10)(\n",
      "...     delayed(sleep)(.2) for _ in range(10)) #doctest: +SKIP\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    1.4s finished\n",
      "\n",
      "Traceback example, note how the line of the error is indicated\n",
      "as well as the values of the parameter passed to the function that\n",
      "triggered the exception, even though the traceback happens in the\n",
      "child process:\n",
      "\n",
      ">>> from heapq import nlargest\n",
      ">>> from joblib import Parallel, delayed\n",
      ">>> Parallel(n_jobs=2)(\n",
      "... delayed(nlargest)(2, n) for n in (range(4), 'abcde', 3))\n",
      "... # doctest: +SKIP\n",
      "-----------------------------------------------------------------------\n",
      "Sub-process traceback:\n",
      "-----------------------------------------------------------------------\n",
      "TypeError                                      Mon Nov 12 11:37:46 2012\n",
      "PID: 12934                                Python 2.7.3: /usr/bin/python\n",
      "........................................................................\n",
      "/usr/lib/python2.7/heapq.pyc in nlargest(n=2, iterable=3, key=None)\n",
      "    419         if n >= size:\n",
      "    420             return sorted(iterable, key=key, reverse=True)[:n]\n",
      "    421\n",
      "    422     # When key is none, use simpler decoration\n",
      "    423     if key is None:\n",
      "--> 424         it = izip(iterable, count(0,-1))           # decorate\n",
      "    425         result = _nlargest(n, it)\n",
      "    426         return map(itemgetter(0), result)          # undecorate\n",
      "    427\n",
      "    428     # General case, slowest method\n",
      " TypeError: izip argument #1 must support iteration\n",
      "_______________________________________________________________________\n",
      "\n",
      "\n",
      "Using pre_dispatch in a producer/consumer situation, where the\n",
      "data is generated on the fly. Note how the producer is first\n",
      "called 3 times before the parallel loop is initiated, and then\n",
      "called to generate new data on the fly:\n",
      "\n",
      ">>> from math import sqrt\n",
      ">>> from joblib import Parallel, delayed\n",
      ">>> def producer():\n",
      "...     for i in range(6):\n",
      "...         print('Produced %s' % i)\n",
      "...         yield i\n",
      ">>> out = Parallel(n_jobs=2, verbose=100, pre_dispatch='1.5*n_jobs')(\n",
      "...     delayed(sqrt)(i) for i in producer()) #doctest: +SKIP\n",
      "Produced 0\n",
      "Produced 1\n",
      "Produced 2\n",
      "[Parallel(n_jobs=2)]: Done 1 jobs     | elapsed:  0.0s\n",
      "Produced 3\n",
      "[Parallel(n_jobs=2)]: Done 2 jobs     | elapsed:  0.0s\n",
      "Produced 4\n",
      "[Parallel(n_jobs=2)]: Done 3 jobs     | elapsed:  0.0s\n",
      "Produced 5\n",
      "[Parallel(n_jobs=2)]: Done 4 jobs     | elapsed:  0.0s\n",
      "[Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s remaining: 0.0s\n",
      "[Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s finished\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Parameters\n",
      "----------\n",
      "depth: int, optional\n",
      "    The depth of objects printed.\n",
      "name: str, optional\n",
      "    The namespace to log to. If None, defaults to joblib.\n",
      "\u001b[0;31mCall docstring:\u001b[0m Main function to dispatch parallel tasks."
     ]
    }
   ],
   "source": [
    "p?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m Decorator used to capture the arguments of a function.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/code/miku/pyflow/.venv/lib/python3.12/site-packages/joblib/parallel.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "delayed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "f = delayed(sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<function math.sqrt(x, /)>, (0,), {}),\n",
       " (<function math.sqrt(x, /)>, (1,), {}),\n",
       " (<function math.sqrt(x, /)>, (4,), {}),\n",
       " (<function math.sqrt(x, /)>, (9,), {}),\n",
       " (<function math.sqrt(x, /)>, (16,), {}),\n",
       " (<function math.sqrt(x, /)>, (25,), {}),\n",
       " (<function math.sqrt(x, /)>, (36,), {}),\n",
       " (<function math.sqrt(x, /)>, (49,), {}),\n",
       " (<function math.sqrt(x, /)>, (64,), {}),\n",
       " (<function math.sqrt(x, /)>, (81,), {})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f(i**2) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p([(lambda x: x + 1, (1,), {})])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memoization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def costly_compute(data, column_index=0):\n",
    "    \"\"\"Simulate an expensive computation\"\"\"\n",
    "    time.sleep(5)\n",
    "    return data[column_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function took 5.00 s to compute.\n",
      "\n",
      "The transformed data are:\n",
      " [ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337 -0.23413696\n",
      "  1.57921282  0.76743473 -0.46947439  0.54256004]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "data = rng.randn(int(1e5), 10)\n",
    "start = time.time()\n",
    "data_trans = costly_compute(data)\n",
    "end = time.time()\n",
    "\n",
    "print('\\nThe function took {:.2f} s to compute.'.format(end - start))\n",
    "print('\\nThe transformed data are:\\n {}'.format(data_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function took 5.03 s to compute.\n",
      "\n",
      "The transformed data are:\n",
      " [ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337 -0.23413696\n",
      "  1.57921282  0.76743473 -0.46947439  0.54256004]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Memory\n",
    "location = './cachedir'\n",
    "memory = Memory(location, verbose=0)\n",
    "\n",
    "\n",
    "def costly_compute_cached(data, column_index=0):\n",
    "    \"\"\"Simulate an expensive computation\"\"\"\n",
    "    time.sleep(5)\n",
    "    return data[column_index]\n",
    "\n",
    "\n",
    "costly_compute_cached = memory.cache(costly_compute_cached)\n",
    "start = time.time()\n",
    "data_trans = costly_compute_cached(data)\n",
    "end = time.time()\n",
    "\n",
    "print('\\nThe function took {:.2f} s to compute.'.format(end - start))\n",
    "print('\\nThe transformed data are:\\n {}'.format(data_trans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Memory(location=./cachedir/joblib)]: Flushing completely the cache\n"
     ]
    }
   ],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "\n",
    "savedir = mkdtemp()\n",
    "\n",
    "import os\n",
    "\n",
    "filename = os.path.join(savedir, 'test.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "to_persist = [('a', [1, 2, 3]), ('b', np.arange(10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpm4wdura4/test.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(to_persist, filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', [1, 2, 3]), ('b', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
